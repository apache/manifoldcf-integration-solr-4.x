<html>
<body>

<p>This module enables search result grouping with Lucene, where hits
with the same value in the specified single-valued group field are
grouped together.  For example, if you group by the <code>author</code>
field, then all documents with the same value in the <code>author</code>
field fall into a single group.</p>

<p>Grouping requires a number of inputs:</p>

  <ul>
    <li> <code>groupField</code>: this is the field used for grouping.
      For example, if you use the <code>author</code> field then each
      group has all books by the same author.  Documents that don't
      have this field are grouped under a single group with
      a <code>null</code> group value.

    <li> <code>groupSort</code>: how the groups are sorted.  For sorting
      purposes, each group is "represented" by the highest-sorted
      document according to the <code>groupSort</code> within it.  For
      example, if you specify "price" (ascending) then the first group
      is the one with the lowest price book within it.  Or if you
      specify relevance group sort, then the first group is the one
      containing the highest scoring book.

    <li> <code>topNGroups</code>: how many top groups to keep.  For
      example, 10 means the top 10 groups are computed.

    <li> <code>groupOffset</code>: which "slice" of top groups you want to
      retrieve.  For example, 3 means you'll get 7 groups back
      (assuming <code>topNGroups</code> is 10).  This is useful for
      paging, where you might show 5 groups per page.

    <li> <code>withinGroupSort</code>: how the documents within each group
      are sorted.  This can be different from the group sort.

    <li> <code>maxDocsPerGroup</code>: how many top documents within each
      group to keep.

    <li> <code>withinGroupOffset</code>: which "slice" of top
      documents you want to retrieve from each group.

  </ul>

<p>
There are two grouping implementations here:
<ul>
  <li>
    Arbitrary grouping that can group by any single-valued indexed
    field, implemented as a two-pass collector: the first pass ({@link
    org.apache.lucene.search.grouping.FirstPassGroupingCollector})
    gathers the top groups, and the second pass ({@link
    org.apache.lucene.search.grouping.SecondPassGroupingCollector})
    gathers documents within those groups.  If the search is costly to
    run you may want to use the {@link
    org.apache.lucene.search.CachingCollector} class, which caches
    hits and can (quickly) replay them for the second pass.  This way
    you only run the query once, but you pay a RAM cost to (briefly)
    hold all hits.  Results are returned as a {@link
    org.apache.lucene.search.grouping.TopGroups} instance.</p>
  </li>
  <li>
    Indexed groups, using a single pass collector (<code>BlockGroupingCollectorDoc</code>) that
    is able to group according to the doc blocks created during
    indexing using <code>IndexWriter</code>'s <code>add/updateDocuments</code> API.
    This is faster (~25% faster QPS) than the generic two-pass
    collector, but it only works for doc blocks so you must statically
    commit (during indexing) to which grouping you'll need at search
    time.

    <p>This implementation does not rely on a single valued grouping
    field; rather, the blocks in the index define the groups, so your
    application is free to determine what the grouping criteria is.
    At search time, you must provide a <code>Filter</code> that marks
    the last document in each group.  This is a substantial memory
    savings because this collector does not load
    a <code>DocTermsIndex</code> from the
    <code>FieldCache</code>.
  </li>
</ul>

<p>The benefit of the arbitrary grouping implementation is you don't have
to commit at indexing time to a static grouping of your documents.
But the downside is it's somewhat slower to run, and requires more RAM
(a <code>FieldCache.DocTermsIndex</code> entry is created).

<p>Known limitations:</p>
<ul>
  <li> For the two-pass grouping collector, the group field must be a
    single-valued indexed field.
  <li> Unlike Solr's implementation, this module cannot group by
    function query values nor by arbitrary queries.
  <li> Sharding is not directly supported, though is not too
    difficult, if you can merge the top groups and top documents per
    group yourself.
</ul>

<p>Typical usage for the generic two-pass collector looks like this
  (using the {@link org.apache.lucene.search.CachingCollector}):</p>

<pre class="prettyprint">
  FirstPassGroupingCollector c1 = new FirstPassGroupingCollector("author", groupSort, groupOffset+topNGroups);

  boolean cacheScores = true;
  double maxCacheRAMMB = 4.0;
  CachingCollector cachedCollector = CachingCollector.create(c1, cacheScores, maxCacheRAMMB);
  s.search(new TermQuery(new Term("content", searchTerm)), cachedCollector);

  Collection<SearchGroup> topGroups = c1.getTopGroups(groupOffset, fillFields);

  if (topGroups == null) {
    // No groups matched
    return;
  }

  boolean getScores = true;
  boolean getMaxScores = true;
  boolean fillFields = true;
  SecondPassGroupingCollector c2 = new SecondPassGroupingCollector("author", topGroups, groupSort, docSort, docOffset+docsPerGroup, getScores, getMaxScores, fillFields);

  //Optionally compute total group count
  AllGroupsCollector allGroupsCollector = null;
  if (requiredTotalGroupCount) {
    allGroupsCollector = new AllGroupsCollector("author");
    c2 = MultiCollector.wrap(c2, allGroupsCollector);
  }

  if (cachedCollector.isCached()) {
    // Cache fit within maxCacheRAMMB, so we can replay it:
    cachedCollector.replay(c2);
  } else {
    // Cache was too large; must re-execute query:
    s.search(new TermQuery(new Term("content", searchTerm)), c2);
  }
        
  TopGroups groupsResult = c2.getTopGroups(docOffset);
  if (requiredTotalGroupCount) {
    groupResult = new TopGroups(groupsResult, allGroupsCollector.getGroupCount());
  }

  // Render groupsResult...
</pre>

<p>To use the single-pass <code>BlockGroupingCollector</code>,
   first, at indexing time, you must ensure all docs in each group
   are added as a block, and you have some way to find the last
   document of each group.  One simple way to do this is to add a
   marker binary field:</p>

<pre class="prettyprint">
  // Create Documents from your source:
  List&lt;Document&gt; oneGroup = ...;
  
  Field groupEndField = new Field("groupEnd", "x", Field.Store.NO, Field.Index.NOT_ANALYZED);
  groupEndField.setOmitTermFreqAndPositions(true);
  groupEndField.setOmitNorms(true);
  oneGroup.get(oneGroup.size()-1).add(groupEndField);

  // You can also use writer.updateDocuments(); just be sure you
  // replace an entire previous doc block with this new one.  For
  // example, each group could have a "groupID" field, with the same
  // value for all docs in this group:
  writer.addDocuments(oneGroup);
</pre>

Then, at search time, do this up front:

<pre class="prettyprint">
  // Set this once in your app & save away for reusing across all queries:
  Filter groupEndDocs = new CachingWrapperFilter(new QueryWrapperFilter(new TermQuery(new Term("end", "x"))));
</pre>

Finally, do this per search:

<pre class="prettyprint">
  // Per search:
  BlockGroupingCollector c = new BlockGroupingCollector(groupSort, groupOffset+topNGroups, needsScores, groupEndDocs);
  s.search(new TermQuery(new Term("content", searchTerm)), c);
  TopGroups groupsResult = c.getTopGroups(withinGroupSort, groupOffset, docOffset, docOffset+docsPerGroup, fillFields);

  // Render groupsResult...
</pre>

Note that the <code>groupValue</code> of each <code>GroupDocs</code>
will be <code>null</code>, so if you need to present this value you'll
have to separately retrieve it (for example using stored
fields, <code>FieldCache</code>, etc.).

</body>
</html>
